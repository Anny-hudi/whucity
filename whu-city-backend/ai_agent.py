"""
AI é¢„è­¦ Agent
åŸºäºé˜¿é‡Œç™¾ç‚¼ API å®ç°åŸå¸‚æ•°æ®åˆ†æå’Œé¢„è­¦å»ºè®®
"""
import json
import dashscope
from dashscope import Generation
from typing import Dict, List, Optional
from config import DASHSCOPE_API_KEY, AI_MODEL, AI_TEMPERATURE, AI_MAX_TOKENS

# åˆå§‹åŒ–é˜¿é‡Œç™¾ç‚¼ SDK
dashscope.api_key = DASHSCOPE_API_KEY


class CityWarningAgent:
    """åŸå¸‚é¢„è­¦ AI Agent"""
    
    def __init__(self):
        self.model = AI_MODEL
        self.temperature = AI_TEMPERATURE
        self.max_tokens = AI_MAX_TOKENS
    
    def analyze_city_data(self, stats_data: Dict, include_balance: bool = False) -> Dict:
        """
        åˆ†æåŸå¸‚æ•°æ®å¹¶ç”Ÿæˆé¢„è­¦å’Œå»ºè®®
        
        Args:
            stats_data: åŒ…å«åŸå¸‚ç»Ÿè®¡æ•°æ®çš„å­—å…¸
                - carbon: ç¢³ç§¯åˆ†
                - biodiversity: ç”Ÿç‰©å¤šæ ·æ€§
                - culture: äººæ–‡å€¼
                - totalScore: æ€»è¯„åˆ†
                - (å¯é€‰) population: äººå£
                - (å¯é€‰) pollution: æ±¡æŸ“å€¼
                - (å¯é€‰) economy: ç»æµå€¼
        
        Returns:
            åŒ…å«é¢„è­¦å’Œå»ºè®®çš„å­—å…¸
        """
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(stats_data, include_balance)
        
        # é‡è¯•æœºåˆ¶
        max_retries = 3
        retry_delay = 2  # ç§’
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ å°è¯•è°ƒç”¨é˜¿é‡Œç™¾ç‚¼ API (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)...")
                print(f"ğŸ“ æ¨¡å‹: {self.model}, æç¤ºè¯é•¿åº¦: {len(prompt)}")
                print(f"ğŸ”‘ API Key: {DASHSCOPE_API_KEY[:10]}...")
                
                # è°ƒç”¨é˜¿é‡Œç™¾ç‚¼ APIï¼ˆæ·»åŠ è¶…æ—¶è®¾ç½®ï¼‰
                import dashscope
                # è®¾ç½®è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
                dashscope.default_timeout = 60
                
                response = Generation.call(
                    model=self.model,
                    prompt=prompt,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    result_format='message',
                    timeout=(10, 60)  # (è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
                )
                
                print(f"ğŸ“¡ API å“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    # æ£€æŸ¥å“åº”æ ¼å¼
                    if not hasattr(response, 'output') or response.output is None:
                        raise Exception("API å“åº”ä¸­æ²¡æœ‰ output å­—æ®µ")
                    
                    if not hasattr(response.output, 'choices') or not response.output.choices:
                        raise Exception("API å“åº”ä¸­æ²¡æœ‰ choices å­—æ®µ")
                    
                    if len(response.output.choices) == 0:
                        raise Exception("API å“åº”ä¸­ choices ä¸ºç©º")
                    
                    # è§£æ AI è¿”å›çš„å†…å®¹
                    choice = response.output.choices[0]
                    if not hasattr(choice, 'message') or not hasattr(choice.message, 'content'):
                        raise Exception("API å“åº”æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ message.content")
                    
                    ai_content = choice.message.content
                    print(f"âœ… AI å“åº”æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(ai_content)}")
                    print(f"ğŸ“„ AI å“åº”å†…å®¹é¢„è§ˆ: {ai_content[:200]}...")
                    return self._parse_ai_response(ai_content, stats_data)
                else:
                    error_msg = f"API è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}"
                    if hasattr(response, 'message'):
                        error_msg += f", æ¶ˆæ¯: {response.message}"
                    print(f"âŒ {error_msg}")
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»§ç»­é‡è¯•
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        import time
                        time.sleep(retry_delay)
                        continue
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™çº§
                        raise Exception(f"API è°ƒç”¨å¤±è´¥: {error_msg}")
                
            except (ConnectionError, ConnectionResetError, OSError) as e:
                error_type = type(e).__name__
                error_detail = f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {error_type}: {str(e)}"
                print(f"ğŸ”Œ {error_detail}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥é‡ç½®é”™è¯¯
                if 'Connection reset' in str(e) or 'Connection aborted' in str(e):
                    print(f"âš ï¸ æ£€æµ‹åˆ°è¿æ¥é‡ç½®é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œä¸ç¨³å®šæˆ–æœåŠ¡å™¨ç«¯æ–­å¼€è¿æ¥")
                    print(f"ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ç¨åé‡è¯•")
                
                if attempt < max_retries - 1:
                    # è¿æ¥é”™è¯¯æ—¶å¢åŠ ç­‰å¾…æ—¶é—´
                    wait_time = retry_delay * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"è¿æ¥å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_detail}")
                    
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                error_detail = f"{error_type}: {error_msg}"
                print(f"âŒ AI Agent é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {error_detail}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥ç›¸å…³é”™è¯¯
                connection_errors = ['Connection', 'timeout', 'reset', 'aborted', 'refused']
                is_connection_error = any(err in error_msg for err in connection_errors)
                
                if is_connection_error:
                    print(f"âš ï¸ æ£€æµ‹åˆ°è¿æ¥ç›¸å…³é”™è¯¯")
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (attempt + 1)
                        print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        import time
                        time.sleep(wait_time)
                        continue
                
                # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆ
                import traceback
                print("ğŸ“‹ å®Œæ•´é”™è¯¯å †æ ˆ:")
                traceback.print_exc()
                
                if attempt < max_retries - 1 and not is_connection_error:
                    print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    import time
                    time.sleep(retry_delay)
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™çº§
                    raise Exception(f"AI Agent è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_detail}")
        
        # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†å®‰å…¨
        raise Exception("AI Agent è°ƒç”¨å¤±è´¥ï¼ŒæœªçŸ¥é”™è¯¯")
    
    def _build_prompt(self, stats_data: Dict, include_balance: bool = False) -> str:
        """æ„å»º AI æç¤ºè¯"""
        carbon = stats_data.get('carbon', 0)
        biodiversity = stats_data.get('biodiversity', 0)
        culture = stats_data.get('culture', 0)
        total_score = stats_data.get('totalScore', 0)
        balance = stats_data.get('balance', 0)
        
        balance_info = ""
        if include_balance and balance is not None:
            balance_info = f"\n- ç©å®¶ä½™é¢ï¼š{balance}ï¼ˆè¿™æ˜¯ç©å®¶å¯ç”¨äºå»ºè®¾çš„èµ„æºï¼Œå»ºè®®éœ€è¦è€ƒè™‘æˆæœ¬ï¼‰"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŸå¸‚è§„åˆ’å’Œç”Ÿæ€ç®¡ç† AI åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹åŸå¸‚æ•°æ®ï¼Œå¹¶æä¾›é¢„è­¦å’Œå»ºè®¾å»ºè®®ã€‚

åŸå¸‚æ•°æ®ï¼š
- ç¢³ç§¯åˆ†ï¼š{carbon}
- ç”Ÿç‰©å¤šæ ·æ€§ï¼š{biodiversity}
- äººæ–‡å€¼ï¼š{culture}
- æ€»è¯„åˆ†ï¼š{total_score}{balance_info}

è¯·æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "warnings": [
        {{
            "level": "low|medium|high|critical",
            "type": "ecology|humanistic|economy|pollution|other",
            "title": "é¢„è­¦æ ‡é¢˜",
            "message": "è¯¦ç»†é¢„è­¦ä¿¡æ¯",
            "metric": "carbon|biodiversity|culture|totalScore"
        }}
    ],
    "suggestions": [
        {{
            "priority": "high|medium|low",
            "category": "ecology|humanistic|economy|infrastructure",
            "title": "å»ºè®®æ ‡é¢˜",
            "description": "è¯¦ç»†å»ºè®®å†…å®¹",
            "action": "å…·ä½“å¯æ‰§è¡Œçš„å»ºè®¾å»ºè®®"
        }}
    ],
    "summary": "æ•´ä½“åŸå¸‚çŠ¶å†µæ€»ç»“ï¼ˆ100å­—ä»¥å†…ï¼‰",
    "trend": "improving|stable|declining",
    "nextSteps": ["ä¸‹ä¸€æ­¥è¡ŒåŠ¨1", "ä¸‹ä¸€æ­¥è¡ŒåŠ¨2"]
}}

è¦æ±‚ï¼š
1. æ ¹æ®æ•°æ®å€¼åˆ¤æ–­é¢„è­¦çº§åˆ«ï¼ˆcritical: ä¸¥é‡é—®é¢˜, high: éœ€è¦å…³æ³¨, medium: ä¸€èˆ¬é—®é¢˜, low: è½»å¾®æé†’ï¼‰
2. æä¾›3-5æ¡å…·ä½“çš„å»ºè®¾å»ºè®®
3. å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ
4. é‡ç‚¹å…³æ³¨ç”Ÿæ€å¹³è¡¡å’Œå¯æŒç»­å‘å±•
5. å¦‚æœæŸä¸ªæŒ‡æ ‡è¿‡ä½ï¼Œç»™å‡ºé’ˆå¯¹æ€§çš„æå‡å»ºè®®
{f"6. å¦‚æœæä¾›äº†ç©å®¶ä½™é¢ï¼Œè¯·åœ¨å»ºè®®ä¸­è€ƒè™‘æˆæœ¬ï¼Œä¼˜å…ˆæ¨èæ€§ä»·æ¯”é«˜çš„å»ºè®¾æ–¹æ¡ˆï¼Œé¿å…è¶…å‡ºé¢„ç®—çš„å»ºè®®" if include_balance and balance else ""}

è¯·ç›´æ¥è¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""

        return prompt
    
    def _parse_ai_response(self, ai_content: str, stats_data: Dict) -> Dict:
        """è§£æ AI è¿”å›çš„å†…å®¹"""
        try:
            # å°è¯•æå– JSONï¼ˆAI å¯èƒ½è¿”å›å¸¦ markdown ä»£ç å—çš„å†…å®¹ï¼‰
            content = ai_content.strip()
            
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            
            content = content.strip()
            
            # è§£æ JSON
            result = json.loads(content)
            
            # æ·»åŠ æ—¶é—´æˆ³å’Œå…ƒæ•°æ®
            result['timestamp'] = self._get_timestamp()
            result['dataSnapshot'] = stats_data
            
            return result
            
        except json.JSONDecodeError as e:
            print(f"JSON è§£æé”™è¯¯: {e}")
            print(f"AI è¿”å›å†…å®¹: {ai_content}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é¢„è­¦
            return self._generate_fallback_warning(stats_data)
    
    def _generate_fallback_warning(self, stats_data: Dict) -> Dict:
        """ç”ŸæˆåŸºç¡€é¢„è­¦ï¼ˆå½“ AI è°ƒç”¨å¤±è´¥æ—¶ï¼‰"""
        warnings = []
        suggestions = []
        
        carbon = stats_data.get('carbon', 0)
        biodiversity = stats_data.get('biodiversity', 0)
        culture = stats_data.get('culture', 0)
        total_score = stats_data.get('totalScore', 0)
        
        # åŸºäºè§„åˆ™çš„åŸºç¡€é¢„è­¦
        if carbon < 500:
            warnings.append({
                "level": "high",
                "type": "ecology",
                "title": "ç¢³ç§¯åˆ†ä¸è¶³",
                "message": f"å½“å‰ç¢³ç§¯åˆ†ä¸º {carbon}ï¼Œå»ºè®®å¢åŠ ç»¿åŒ–å»ºè®¾ä»¥æå‡ç”Ÿæ€å€¼",
                "metric": "carbon"
            })
            suggestions.append({
                "priority": "high",
                "category": "ecology",
                "title": "å¢åŠ ç»¿åŒ–å»ºè®¾",
                "description": "é€šè¿‡ç§æ¤æ ‘æœ¨ã€å»ºè®¾å…¬å›­ç­‰æ–¹å¼æå‡ç¢³ç§¯åˆ†",
                "action": "åœ¨ç©ºåœ°ä¸Šå»ºè®¾æ›´å¤šç»¿åŒ–è®¾æ–½"
            })
        
        if biodiversity < 50:
            warnings.append({
                "level": "medium",
                "type": "ecology",
                "title": "ç”Ÿç‰©å¤šæ ·æ€§åä½",
                "message": f"å½“å‰ç”Ÿç‰©å¤šæ ·æ€§ä¸º {biodiversity}ï¼Œå»ºè®®å¢åŠ ç”Ÿæ€å¤šæ ·æ€§",
                "metric": "biodiversity"
            })
            suggestions.append({
                "priority": "medium",
                "category": "ecology",
                "title": "æå‡ç”Ÿç‰©å¤šæ ·æ€§",
                "description": "å»ºè®¾æ›´å¤šç”Ÿæ€è®¾æ–½ï¼Œå¸å¼•æ›´å¤šç”Ÿç‰©",
                "action": "å»ºè®¾ç”Ÿæ€å…¬å›­ã€æ¹¿åœ°ç­‰ç”Ÿæ€è®¾æ–½"
            })
        
        if culture < 50:
            warnings.append({
                "level": "medium",
                "type": "humanistic",
                "title": "äººæ–‡å€¼åä½",
                "message": f"å½“å‰äººæ–‡å€¼ä¸º {culture}ï¼Œå»ºè®®å¢åŠ æ–‡åŒ–è®¾æ–½å»ºè®¾",
                "metric": "culture"
            })
            suggestions.append({
                "priority": "medium",
                "category": "humanistic",
                "title": "å¢åŠ æ–‡åŒ–è®¾æ–½",
                "description": "å»ºè®¾å›¾ä¹¦é¦†ã€åšç‰©é¦†ç­‰æ–‡åŒ–è®¾æ–½æå‡äººæ–‡å€¼",
                "action": "åœ¨åŸå¸‚ä¸­å»ºè®¾æ›´å¤šæ–‡åŒ–å»ºç­‘"
            })
        
        if total_score < 50:
            warnings.append({
                "level": "critical",
                "type": "other",
                "title": "åŸå¸‚ç»¼åˆè¯„åˆ†åä½",
                "message": f"å½“å‰æ€»è¯„åˆ†ä¸º {total_score}ï¼Œéœ€è¦å…¨é¢æå‡å„é¡¹æŒ‡æ ‡",
                "metric": "totalScore"
            })
        
        return {
            "warnings": warnings,
            "suggestions": suggestions,
            "summary": f"åŸå¸‚å½“å‰çŠ¶æ€ï¼šç¢³ç§¯åˆ† {carbon}ï¼Œç”Ÿç‰©å¤šæ ·æ€§ {biodiversity}ï¼Œäººæ–‡å€¼ {culture}ï¼Œæ€»è¯„åˆ† {total_score}ã€‚éœ€è¦å…³æ³¨ç”Ÿæ€å’Œäººæ–‡å»ºè®¾ã€‚",
            "trend": "stable",
            "nextSteps": ["æå‡ç¢³ç§¯åˆ†", "å¢åŠ ç”Ÿç‰©å¤šæ ·æ€§", "å»ºè®¾æ–‡åŒ–è®¾æ–½"],
            "timestamp": self._get_timestamp(),
            "dataSnapshot": stats_data,
            "fallback": True  # æ ‡è®°è¿™æ˜¯å¤‡ç”¨æ–¹æ¡ˆ
        }
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()


# åˆ›å»ºå…¨å±€ agent å®ä¾‹
agent = CityWarningAgent()

